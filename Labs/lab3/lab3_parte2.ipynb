{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKt8AdJpR0Ly"
      },
      "source": [
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "in_colab = True\n",
        "import os\n",
        "if not in_colab:\n",
        "    import sys ; sys.path.append('../commons/utils/'); sys.path.append('../commons/utils/data')\n",
        "else: \n",
        "    os.system('wget https://raw.githubusercontent.com/mariabda2/ML_2022/master/Labs/commons/utils/general.py -O general.py')\n",
        "    from general import configure_lab3\n",
        "    configure_lab3()\n",
        "from lab3 import *\n",
        "GRADER = part_2()\n",
        "sns.set_context('talk')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-8jBq_KR0L1"
      },
      "source": [
        "# Laboratorio 3 - Parte 2. Comparación de metodos basados en árboles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkbHQloLR0L2"
      },
      "source": [
        "A continuación se leen los datos de un problema de clasificación, usando los datos de analisis quimico de diferentes vinos. Como siempre [explora un poco el contenido y caracteristicas de nuestro conjunto de datos](https://archive.ics.uci.edu/ml/datasets/wine).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hwo-dBVfR0L2"
      },
      "outputs": [],
      "source": [
        "x, y =  load_wine(return_X_y = True)\n",
        "print(x.shape, \"\\n\", x[0:3])\n",
        "print(y[0:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGgD-28CR0L4"
      },
      "source": [
        "## Ejercicio 1 Experimentos con Arboles de decisión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXpaZfqCR0L4"
      },
      "source": [
        "Debe consultar todo lo relacionado con la creación, entrenamiento y uso en predicción de este modelo usando la librería scikit-learn. En este enlace, se puede leer la documentación http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html.\n",
        "\n",
        "En el notebook, ya se encuentra cargada la libreria:\n",
        "\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "```\n",
        "\n",
        "Las siguientes preguntas abiertas, buscan verificar que se está haciendo un contraste con la librería y la teoría, por lo tanto procura incluir conceptos asociados y **NO** solo enfocarse en las descripciones de la documentación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cuáles de los parámetros en la librería pueden ayudar a controlar el crecimiento del árbol de decisión (DT-Decision Tree)?\n",
        "#@markdown ¿Cual de las opciones está mejor justificada?\n",
        " \n",
        "#@markdown A) `criterion` es el parámetro que tiene más influencia ya que es el que decide medida para ganancia de información\n",
        " \n",
        "#@markdown B) `max_depth` es el que tiene mayor influencia, controlando el número total de nodos del DT el resto de parámetros pueden influenciar pero no de manera directa.\n",
        " \n",
        "#@markdown C) `max_depth`, `min_samples_split y `min_samples_leaf son importantes ya influencia en la creación de splits, aunque hay otros. `max_depth` es el que tiene mayor influencia, controlando el número total de nodos del DT.\n",
        " \n",
        "#@markdown D) `max_depth` es el que tiene mayor influencia, controlando el número total de nodos del DT, luego  `max_features` que nos indica el máximo de características usadas.\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_1 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_TuOF2vXR0L6"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cuál es la diferencia principal entre `min_impurity_decrease` y `min_samples_split`? ¿cual tiene influencia en el número de nodos?\n",
        "respuesta_2 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIw79WykR0L8"
      },
      "source": [
        "En la siguiente celda se define una simulación para entrenar y validar un modelo usando los datos previamente cargados. Complete el código para usar como modelo de predicción un arbol de decisión.\n",
        "\n",
        "<b>Note</b> que existe una clase para modelos de clasificación y otra para modelos de regresión:\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "\n",
        "Vamos a tener en cuenta lo siguiente:\n",
        "1. dentro del código, ya se encuentra sugerida la metodologia de validación\n",
        "2. la función va aceptar un parametro `str`, para seleccionar tipo de normalización.\n",
        "    1. Estandar\n",
        "    2. Minimo y maximos\n",
        "3. **hacer uso explicito del nombre del parametro que se va usar**, por ejemplo, si se requeire asignar el parametro `max_features`  debemos llamar la libreria de esta manera: `DecisionTreeClassifier(max_features = 'auto')`\n",
        "4. Vamos a configurar el arbol con la medida de impureza Entropia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lD0jyrER0L8"
      },
      "outputs": [],
      "source": [
        "#ejercicio de código\n",
        "def experimentar_dt( X, Y, depths,normalize):\n",
        "    \"\"\"funcion que realiza experimentos de arboles de decision\n",
        "    Args:\n",
        "        X: matriz con las caractersiticas\n",
        "        Y: matriz de numpy con etiquetas\n",
        "        depths: list[int] lista con la profundidad de arboles a experimentar\n",
        "    normalize str: None, significa nignuna normalización. 'estandar'. 'min-max' los otros dos tipos\n",
        "    retorna: dataframe con:\n",
        "        - profunidad de los arboles\n",
        "        - eficiencia de entrenamiento\n",
        "        - desviacion de estandar eficiencia de entrenamiento\n",
        "        - eficiencia de prueba\n",
        "        - desviacion estandar eficiencia de prueba\n",
        "    \"\"\"\n",
        "    folds = 4\n",
        "    skf = StratifiedKFold(n_splits=folds)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for depth in depths:\n",
        "        ## para almacenar los errores intermedios\n",
        "        EficienciaTrain = []\n",
        "        EficienciaVal = []\n",
        "        for train, test in skf.split(X, Y):\n",
        "            Xtrain = X[train,:]\n",
        "            Ytrain = Y[train]\n",
        "            Xtest = X[test,:]\n",
        "            Ytest = Y[test]\n",
        "            #Normalizamos los datos\n",
        "            # si la bandera esta en True\n",
        "            scaler = None\n",
        "            if normalize == 'estandar':\n",
        "                # usa la clase adecuada\n",
        "                scaler = ...()\n",
        "                scaler.fit(Xtrain)\n",
        "\n",
        "            elif normalize == 'min-max':\n",
        "                # usa la clase adecuada\n",
        "                scaler = ...()\n",
        "            \n",
        "            else:\n",
        "                if idx < 1:\n",
        "                    # solo imprimir la advertencia una vez POR FOLD\n",
        "                    print(\"No se ejecuta niguna normalizacion/estandarizacion\")\n",
        "\n",
        "            if scaler is not None:\n",
        "                scaler.fit(Xtrain)\n",
        "                Xtrain= scaler.transform(Xtrain)\n",
        "                Xtest = scaler.transform(Xtest)\n",
        "    \n",
        "\n",
        "            #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "            modelo = ...(max_depth=depth, criterion=\"entropy\")\n",
        "            modelo...(...)\n",
        "            #predecir muestras de entrenamiento\n",
        "            Ytrain_pred = modelo...(...)\n",
        "            #predecir muestras de pruebas\n",
        "            Ytest_pred = modelo...(X=...)\n",
        "            #Evaluamos las predicciones del modelo con los datos de test\n",
        "            EficienciaTrain.append(np.mean(Ytrain_pred.ravel() == Ytrain.ravel()))\n",
        "            EficienciaVal.append(np.mean(Ytest_pred.ravel() == Ytest.ravel()))\n",
        "\n",
        "        resultados.loc[idx,'profunidad del arbol'] = depth\n",
        "        resultados.loc[idx,'eficiencia de entrenamiento'] = np.mean(EficienciaTrain)\n",
        "        resultados.loc[idx,'desviacion estandar entrenamiento'] = np.std(EficienciaTrain)\n",
        "        resultados.loc[idx,'eficiencia de prueba'] = np.mean(EficienciaVal)\n",
        "        resultados.loc[idx,'desviacion estandar prueba'] = np.std(EficienciaVal)\n",
        "        idx= idx +1\n",
        "        \n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_G3OTVfR0L-"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio1\", experimentar_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf0Fe0uPR0MA"
      },
      "outputs": [],
      "source": [
        "# Realiza los experimentos para observar los efectos\n",
        "\n",
        "resultados_dt = []\n",
        "depths = [10,20,30,50]\n",
        "normalizaciones = ['ninguna', 'estandar', 'min-max']\n",
        "\n",
        "for normalize in normalizaciones:\n",
        "    # usa tu funcion\n",
        "    resultados_parciales = ... (X = x , Y = y, depths = depths, normalize=normalize)\n",
        "    resultados_parciales['normalizacion'] = normalize\n",
        "    resultados_dt.append(resultados_parciales)\n",
        "\n",
        "resultados_dt = pd.concat(resultados_dt, ignore_index=True)\n",
        "\n",
        "sns.catplot(data = resultados_dt, \n",
        "            x = 'profunidad del arbol', \n",
        "            y = 'eficiencia de prueba', \n",
        "            hue = 'normalizacion' ,\n",
        "            kind = 'point', \n",
        "            aspect = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Tiene algún efecto la normalización o estandarización de las variables en el desempeño del modelo de árboles de decisión?\n",
        "#@markdown ¿Cual de las opciones está mejor justificada? Puedes volver a ejecutar experimentos\n",
        " \n",
        "#@markdown A) Se observan que las diferencias no son muy grandes pero no hay patrón claro, si se vuelve a ejecutar los experimentos los efectos pueden variar, la normalización debe ser tratada como un parámetro más\n",
        " \n",
        "#@markdown B) Se observan que las diferencias son grandes pero hay un patrón claro, si se vuelve a ejecutar los experimentos los efectos no varían, la normalización no tiene influencia ya que los DT no son sensibles a los diferentes rangos entre características\n",
        " \n",
        "#@markdown C) Se observan que las diferencias no son muy grandes, si se vuelve a ejecutar los experimentos los efectos pueden variar, eso se debe a que no estamos configurando un `random_state`, sin embargo la normalización en los DT no tiene tanta influencia porque las comparaciones se hacen entre valores de una misma característica\n",
        " \n",
        "#@markdown D) Se observan que la diferencias son pequeñas y hay un patrón claro, si se vuelve a ejecutar los experimentos los efectos pueden variar, eso se debe a que no estamos configurando un `random_state`, pero sabemos que la normalización en los DT no tiene influencia por que las comparaciones se hacen entre valores de una misma característica\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_3 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a explorar un poco la visualización de los arboles, reemplaza los mejores valores de parametros encontrados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# se usa para visualizar el DT\n",
        "from sklearn import tree\n",
        "# reemplaza el valor\n",
        "mejor_profundidad = ...\n",
        "modelo = DecisionTreeClassifier(max_depth=mejor_profundidad, criterion=\"entropy\", ccp_alpha =...) # reemplaza el valor\n",
        "modelo.fit(x, y)\n",
        "tree.plot_tree(modelo,filled = True,class_names = classes_wines(), feature_names= features_wines())\n",
        "print(\"ccp_alpha = 0.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# se usa para visualizar el DT\n",
        "from sklearn import tree\n",
        "modelo = DecisionTreeClassifier(max_depth=mejor_profundidad, criterion=\"entropy\", ccp_alpha =...) # reemplaza el valor\n",
        "modelo.fit(x, y)\n",
        "tree.plot_tree(modelo,filled = True,class_names = classes_wines(), feature_names=features_wines())\n",
        "print(\"ccp_alpha = 0.5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observa la influencia de el parámetro `ccp_alpha`.  Investiga un poco acerca del concepto de \"Poda\" / Prunning en los DT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿que relación tiene el parámetro `ccp_alpha` y el concepto de \"poda\" de arboles? ¿que efectos practicos tiene el podado de los arboles?\n",
        "respuesta_4 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3sPp3OoR0MF"
      },
      "source": [
        "## Ejercicio 2 Experimentos con Random Forest\n",
        "\n",
        "En la siguiente celda se define una simulación para entrenar y validar un modelo usando los datos previamente cargados. Complete el código para usar como modelo de predicción un Random Forest. Debe consultar todo lo relacionado con la creación, entrenamiento y uso en predicción de este modelo usando la librería scikit-learn. Consultar aquí: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html.\n",
        "\n",
        "En el notebook, ya se encuentra cargada la libreria:\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "```\n",
        "\n",
        "<b>Note</b> que al igual que en el caso anterior, existe una clase para modelos de clasificación y otra para modelos de regresión: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
        "\n",
        "**Recordar hacer uso explicito del nombre del parametro que se va usar**, por ejemplo, si se requiere asignar el parametro `criterion`  debemos llamar la libreria  de esta manera: `RandomForestClassifier(criterion = 'gini')`.\n",
        "\n",
        "Para nuestros experimentos vamos a configurar el RF para que el mínimo de muestras para considerar un nodo como hoja sea de 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMfYwB1VR0MH"
      },
      "outputs": [],
      "source": [
        "#ejercicio de código\n",
        "def experimentar_rf(X, Y, num_trees,numero_de_variables):\n",
        "    \"\"\"funcion que realiza experimentos de random forest\n",
        "    X: matriz con las caractersiticas\n",
        "    Y: matriz de numpy con etiquetas\n",
        "    num_trees: list[int]: lista con el número de arboles usado para el RF\n",
        "    numero_de_variables list[int]: lista con variables para la selección del mejor umbral en cada nodo \n",
        "    retorna: dataframe con:\n",
        "        -  numero de arboles usados\n",
        "        -  variables para la selección del mejor umbral\n",
        "        - eficiencia de entrenamiento\n",
        "        - desviacion de estandar eficiencia de entrenamiento\n",
        "        - eficiencia de prueba\n",
        "        - desviacion estandar eficiencia de prueba\n",
        "    \"\"\"\n",
        "    folds = 4\n",
        "    skf = StratifiedKFold(n_splits=folds)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for trees in num_trees:\n",
        "        for num_variables in numero_de_variables:\n",
        "            ## para almacenar los errores intermedios\n",
        "            EficienciaTrain = []\n",
        "            EficienciaVal = []\n",
        "            for train, test in skf.split(X, Y):\n",
        "                Xtrain = X[train,:]\n",
        "                Ytrain = Y[train]\n",
        "                Xtest = X[test,:]\n",
        "                Ytest = Y[test]\n",
        "                #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "                modelo = ...(...)\n",
        "                modelo...(...)\n",
        "                #predecir muestras de entrenamiento\n",
        "                Ytrain_pred = modelo...(...)\n",
        "                #predecir muestras de pruebas\n",
        "                YtestPred = modelo...(...)\n",
        "                #Evaluamos las predicciones del modelo con los datos de test\n",
        "                EficienciaTrain.append(np.mean(Ytrain_pred.ravel() == Ytrain.ravel()))\n",
        "                EficienciaVal.append(np.mean(YtestPred.ravel() == Ytest.ravel()))\n",
        "\n",
        "            resultados.loc[idx,'número de arboles'] = trees\n",
        "            resultados.loc[idx,'variables para la selección del mejor umbral'] = num_variables\n",
        "            resultados.loc[idx,'eficiencia de entrenamiento'] = np.mean(EficienciaTrain)\n",
        "            resultados.loc[idx,'desviacion estandar entrenamiento'] = np.std(EficienciaTrain)\n",
        "            resultados.loc[idx,'eficiencia de prueba'] = np.mean(EficienciaVal)\n",
        "            resultados.loc[idx,'desviacion estandar prueba'] = np.std(EficienciaVal)\n",
        "            idx= idx +1\n",
        "        print(f\"termina para {trees} arboles\")\n",
        "        \n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SAYXT3hR0MJ"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio2\", experimentar_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS5xALz3R0ML"
      },
      "source": [
        "Una vez completado el código realice los experimentos necesarios para llenar la siguiente tabla:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blO2GTUtR0ML"
      },
      "outputs": [],
      "source": [
        "arboles = [5,20,50,100, 150]\n",
        "variables_seleccion = [2,5,10, x.shape[1]]\n",
        "# reemplaza por la funcion\n",
        "resultados_rf = ... (X=x, Y=y, num_trees = arboles ,numero_de_variables = variables_seleccion)\n",
        "resultados_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TmMypaf9R0MN"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿qué relación tiene `sklearn.ensemble.BaggingClassifier`cuando los son Random forest entrenados con el parametro `max_features=13`?\n",
        "respuesta_5 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEACC0WkR0MO"
      },
      "source": [
        "Vamos a comparar los resultados del RF y con el DT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-UCgRrVR0MP"
      },
      "outputs": [],
      "source": [
        "print(\"diferencia promedio entre entrenamiento y prueba del DT\", \n",
        "      resultados_dt['eficiencia de entrenamiento'].mean() - resultados_dt['eficiencia de prueba'].mean())\n",
        "\n",
        "print(\"diferencia promedio entre entrenamiento y prueba del RF\", \n",
        "      resultados_rf['eficiencia de entrenamiento'].mean()-resultados_rf['eficiencia de prueba'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhwOWjtF1gW9"
      },
      "source": [
        "de acuerdo a estos resultados, que modelo tuvo un mayor sobre entrenamiento?, ten presente esa diferencia para responder la siguiente pregunta abierta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "o_Tz9hz6R0MR"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿esperaba la diferencia que se observa entre las eficiencias entre entrenamiento y pruebas para el Random forest y el arbol de decisón? justifique \n",
        "respuesta_6 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBfC_8rDR0MS"
      },
      "source": [
        "## Ejercicio 3 Experimentos con Gradient Boosted Trees\n",
        "\n",
        "En la siguiente celda se define una simulación para entrenar y validar un modelo usando los datos previamente cargados. Complete el código para usar como modelo de predicción un Gradient boosted Tree. Debe consultar todo lo relacionado con la creación, entrenamiento y uso en predicción de este modelo usando la librería scikit-learn. Consultar aquí: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "\n",
        "En el notebook, ya se encuentra cargada la libreria:\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "```\n",
        "\n",
        "Debemos configurar el árbol con un mínimo de tres (3) muestras para considerar una división de un nodo.\n",
        "\n",
        "<b>Note</b> que al igual que en el caso anterior, existe una clase para modelos de clasificación y otra para modelos de regresión: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n",
        "\n",
        "**Recordar hacer uso explicito del nombre del parametro que se va usar**, por ejemplo, si se requeire asignar el parametro ` loss`  debemos llamar la libreria  de esta manera: `GradientBoostingClassifier(loss = 'deviance')`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfaU0uZPR0MS"
      },
      "outputs": [],
      "source": [
        "#ejercicio de código\n",
        "def experimentar_gbt(num_trees, X, Y):\n",
        "    \"\"\"funcion que realiza experimentos de arboles de decision\n",
        "    num_trees: list[int] lista con el número de arboles usado para el RF\n",
        "    X: matriz con las caractersiticas\n",
        "    Y: matriz de numpy con etiquetas\n",
        "    retorna: dataframe con:\n",
        "        - numero de arboles usados\n",
        "        - eficiencia de entrenamiento\n",
        "        - desviacion de estandar eficiencia de entrenamiento\n",
        "        - eficiencia de prueba\n",
        "        - desviacion estandar eficiencia de prueba\n",
        "    \"\"\"\n",
        "    folds = 4\n",
        "    skf = StratifiedKFold(n_splits=folds)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for trees in num_trees:\n",
        "        ## para almacenar los errores intermedios\n",
        "        EficienciaTrain = []\n",
        "        EficienciaVal = []\n",
        "        for train, test in skf.split(X, Y):\n",
        "            Xtrain = X[train,:]\n",
        "            Ytrain = Y[train]\n",
        "            Xtest = X[test,:]\n",
        "            Ytest = Y[test]\n",
        "            #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "            modelo = ...(...)\n",
        "            modelo...(...)\n",
        "            #predecir muestras de entrenamiento\n",
        "            Ytrain_pred = ...(...)\n",
        "            #predecir muestras de pruebas\n",
        "            Ytest_pred = modelo...(...)\n",
        "            #Evaluamos las predicciones del modelo con los datos de test\n",
        "            EficienciaTrain.append(np.mean(Ytrain_pred.ravel() == Ytrain.ravel()))\n",
        "            EficienciaVal.append(np.mean(Ytest_pred.ravel() == Ytest.ravel()))\n",
        "\n",
        "        resultados.loc[idx,'número de arboles'] = trees\n",
        "        resultados.loc[idx,'eficiencia de entrenamiento'] = np.mean(EficienciaTrain)\n",
        "        resultados.loc[idx,'desviacion estandar entrenamiento'] = np.std(EficienciaTrain)\n",
        "        resultados.loc[idx,'eficiencia de prueba'] =np.mean(EficienciaVal)\n",
        "        resultados.loc[idx,'desviacion estandar prueba'] = np.std(EficienciaVal)\n",
        "        idx= idx +1\n",
        "        \n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu56Q8pKR0MU"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio3\", experimentar_gbt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6vIMbJ7R0MW"
      },
      "outputs": [],
      "source": [
        "# ejecuta para realizar los experimentos\n",
        "resultados_gbt = experimentar_gbt(arboles, x, y)\n",
        "resultados_gbt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E4iUcGwR0MX"
      },
      "source": [
        "Vamos a graficar la eficiencia para el RF y el GBT en función del número de arboles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcYqRudTR0MX"
      },
      "outputs": [],
      "source": [
        "# se crea un df para agrupar los resultados\n",
        "# y graficar las diferencias entre el GBT y el RF\n",
        "rf_res = resultados_rf.groupby(\"número de arboles\")['eficiencia de prueba'].mean().reset_index()\n",
        "rf_res['Tipo'] = 'RF'\n",
        "gbt_res = resultados_gbt.groupby(\"número de arboles\")['eficiencia de prueba'].mean().reset_index()\n",
        "gbt_res['Tipo'] = 'GBT'\n",
        "data_to_plot= pd.concat([rf_res, gbt_res], ignore_index=True)\n",
        "sns.relplot(data=data_to_plot, x= 'número de arboles', y = 'eficiencia de prueba', hue = 'Tipo', kind='line', aspect=1.5,height=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMPFC4H_R0Ma"
      },
      "source": [
        "## Ejercicio 4 Tiempo de entrenamiento del RF y GBT\n",
        "\n",
        "En nuestro último experimento, vamos a evaluar la influencia de las parametros del RF y del GBT en el tiempo de entrenamiento. \n",
        "\n",
        "Para ello vamos a crear una función para medir el tiempo de entrenamiento usando la instrucción `time.process_time()`.\n",
        "\n",
        "Vamos crear la función, para poder evaluar la influencia de:\n",
        "1. número de arboles\n",
        "2. cantidad de variables a analizar por nodo\n",
        "\n",
        "En el entrenamiento del RF y del GBT. \n",
        "\n",
        "**Notar**  \n",
        "1. No vamos a dividir el conjunto, ya que el objetivo es evaluar el tiempo de entrenamiento y no la eficiencias del modelo\n",
        "2. No calculamos las prediciones\n",
        "3. **Recordar hacer uso explicito del nombre del parametro que se va usar**, por ejemplo, si se requeire asignar el parametro `criterion`  debemos llamar la libreria  de esta manera: `RandomForestClassifier(criterion = 'gini')`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOdu_n0wR0Ma"
      },
      "outputs": [],
      "source": [
        "def time_rf_gbt_training(X, Y, num_trees, numero_de_variables, metodo):\n",
        "    \"\"\"funcion que realiza experimentos, para determinar la influencia\n",
        "    del numero de arboles y de caracteristicas en el tiempo de entrenamiento\n",
        "    del RF\n",
        "    X: conjunto de datos para realizar los experimentos\n",
        "    Y: conjunto de etiquetas de clase\n",
        "    num_trees: List[int] lista con el número de arboles a evaluar\n",
        "    num_variables: List[int] lista con el número variables a evaluar\n",
        "    retorna: dataframe con:\n",
        "    - número de arboles\n",
        "    - variables para la selección del mejor umbral\n",
        "    - tiempo de entrenamiento\n",
        "    \"\"\"\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    \n",
        "    for trees in num_trees:\n",
        "        for variables in numero_de_variables:\n",
        "            ## ejecutar 5 veces lo mismo\n",
        "            ## para llegar a un tiempo más adecuado\n",
        "            tiempos = []\n",
        "            for i in range(5):\n",
        "            ## llamar la \n",
        "                start = time.process_time()\n",
        "                if metodo == 'rf':\n",
        "                \n",
        "                    modelo ...\n",
        "                else:\n",
        "                    modelo = ... \n",
        "                modelo.fit(X=X, y=Y)\n",
        "                ## obtener tiempo \n",
        "                end = time.process_time()\n",
        "                # append de la resta de fin y end\n",
        "                tiempos.append( ... )\n",
        "            resultados.loc[idx,'número de arboles'] = trees\n",
        "            resultados.loc[idx,'variables para la selección del mejor umbral'] = variables\n",
        "            resultados.loc[idx,'tiempo de entrenamiento'] = np...(...)\n",
        "            resultados.loc[idx,'metodo'] = metodo\n",
        "            idx = idx +1\n",
        "    return(resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukJ6i-hCR0Mc"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio4\", time_rf_gbt_training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmfXgHHUR0Me"
      },
      "source": [
        "Vamos a dejar fijo el número de variables en 20 y variar los árboles en: [5,10,15,25, 50], completa el código para ver la grafica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK2JdQAfR0Me"
      },
      "outputs": [],
      "source": [
        "resultados_rf_time1 = time_rf_gbt_training(x, y, [5,10,15,25,50], [20], metodo = 'rf')\n",
        "resultados_gbt_time1 = time_rf_gbt_training(x, y, [5,10,15,25,50], [20], metodo = 'gbt')\n",
        "\n",
        "resultados_time = pd.concat([resultados_rf_time1, resultados_gbt_time1], ignore_index=True)\n",
        "\n",
        "sns.relplot(data = resultados_time, x = 'número de arboles', y = 'tiempo de entrenamiento', hue = 'metodo', kind = 'line')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKqJ85TUR0Mf"
      },
      "source": [
        "Y por ultimo Vamos a dejar fijo el número de árboles en 20 y el número de varaibles [5,10,15,20,40], completa el código para ver la grafica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mkj5sbRR0Mg"
      },
      "outputs": [],
      "source": [
        "resultados_rf_time1 = time_rf_gbt_training(x, y, [20], [5,10,15,20,40], metodo = 'rf')\n",
        "resultados_gbt_time1 = time_rf_gbt_training(x, y, [20], [5,10,15,20,40], metodo = 'gbt')\n",
        "\n",
        "resultados_time = pd.concat([resultados_rf_time1, resultados_gbt_time1], ignore_index=True)\n",
        "\n",
        "sns.relplot(data = resultados_time, x = 'variables para la selección del mejor umbral', y = 'tiempo de entrenamiento', hue = 'metodo', kind = 'line')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2aJTJ4GVR0Mh"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿qué parametro de los evaluados tiene una mayor influencia en los tiempos de entrenamiento? ¿hay diferencia entre el RF y GBT? justifique\n",
        "respuesta_7 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GedZDu-A1gW_"
      },
      "outputs": [],
      "source": [
        "GRADER.check_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QeIgW9y2R0Mj"
      },
      "outputs": [],
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPCnjXUGR0Mk"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k67-WjqNR0Ml"
      },
      "outputs": [],
      "source": [
        "GRADER.grade()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab3_parte2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2c18b6e3c0567ae261554fb488d926060588260467d0a9198b0b400cf35be92e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('ml_2022_book')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
